{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Experiment 2\n",
    "# Data cleaning and save the cleaned data into an Excel table, generate images, and store them in the specified folder\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import glob\n",
    "from openpyxl import load_workbook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define function to process a single file\n",
    "abnormal_speed = 2.57\n",
    "abnormal_distance = 48.35  # Distance anomaly; the participant should not move this far\n",
    "settled_distance = 8.5  # The usual distance after teleportation in the initial experimental design\n",
    "def process_file(file_path):\n",
    "    # Define column names based on the observed structure\n",
    "    column_names = [\"Time\", \"ID\", \"Positionx\", \"Positionz\", \"Positiony\", \"Yaw\", \"Up\", \"Right\", \"Down\", \"Left\"]\n",
    "\n",
    "    # Read the CSV file without a header and assign column names\n",
    "    data = pd.read_csv(file_path, header=None, names=column_names)\n",
    "\n",
    "    # Adjust the time\n",
    "    initial_time = data.loc[0, 'Time']\n",
    "    data['Time'] = data['Time'] - initial_time\n",
    "\n",
    "    # Remove parentheses from the Positionx and Positiony columns\n",
    "    data['Positionx'] = data['Positionx'].astype(str).str.replace('(', '').str.replace(')', '')\n",
    "    data['Positiony'] = data['Positiony'].astype(str).str.replace('(', '').str.replace(')', '')\n",
    "\n",
    "    # Ensure the Positiony and Positionx columns contain numeric values after cleaning\n",
    "    data['Positiony'] = pd.to_numeric(data['Positiony'], errors='coerce')\n",
    "    data['Positionx'] = pd.to_numeric(data['Positionx'], errors='coerce')\n",
    "\n",
    "    # Calculate the distance from the origin (0, 0) for each row and create a new 'Distance' column\n",
    "    data['Distance'] = np.sqrt(data['Positionx']**2 + data['Positiony']**2)\n",
    "\n",
    "    # Create an empty list to store indices of rows that need to be marked\n",
    "    highlight_rows = []\n",
    "\n",
    "    # Iterate through the Positiony column and filter rows that meet certain conditions\n",
    "    for i in range(len(data) - 1):\n",
    "        if -1.5 < data.loc[i, 'Positiony'] and abs(data.loc[i, 'Distance'] - data.loc[i + 1, 'Distance']) > 5:\n",
    "            highlight_rows.append(i)\n",
    "            highlight_rows.append(i + 1)\n",
    "\n",
    "    # Create a new column to store labels\n",
    "    data['Label'] = 0\n",
    "\n",
    "    # Assign labels to the rows\n",
    "    current_label = 1\n",
    "    if highlight_rows:\n",
    "        data.loc[:highlight_rows[0], 'Label'] = current_label\n",
    "        for i in range(1, len(highlight_rows), 2):\n",
    "            current_label += 1\n",
    "            start_index = highlight_rows[i] + 1\n",
    "            if i + 1 < len(highlight_rows):\n",
    "                end_index = highlight_rows[i + 1]\n",
    "                data.loc[start_index:end_index, 'Label'] = current_label\n",
    "            else:\n",
    "                data.loc[start_index:, 'Label'] = current_label\n",
    "\n",
    "    # Replace the 0s in the Label column with the previous label\n",
    "    for i in range(1, len(data)):\n",
    "        if data.loc[i, 'Label'] == 0:\n",
    "            data.loc[i, 'Label'] = data.loc[i + 1, 'Label']\n",
    "\n",
    "    # Remove five rows of data (useless data during teleportation)\n",
    "\n",
    "    # Create an empty list to store indices of rows that need to be cleared\n",
    "    clear_rows = []\n",
    "\n",
    "    # Iterate through the Positiony column and filter rows that meet certain conditions\n",
    "    for i in range(len(data) - 1):\n",
    "        if -1.5 < data.loc[i, 'Positiony'] and abs(data.loc[i, 'Distance'] - data.loc[i + 1, 'Distance']) > 5:\n",
    "            for j in range(max(0, i-4), i+1):\n",
    "                clear_rows.append(j)\n",
    "\n",
    "    # Define the columns that need to be kept\n",
    "    columns_to_keep = ['Time', 'ID']\n",
    "\n",
    "    # Clear information but retain Time and ID columns\n",
    "    for row_index in clear_rows:\n",
    "        for col in data.columns:\n",
    "            if col not in columns_to_keep:\n",
    "                data.at[row_index, col] = np.nan  # This clears the content\n",
    "\n",
    "    # Calculate the speed (positionx, positiony) at each time unit\n",
    "    # Create a new Speed column\n",
    "    data['Speed'] = np.nan\n",
    "\n",
    "    # Iterate through the DataFrame and calculate the speed\n",
    "    for i in range(1, len(data)):\n",
    "        if pd.notna(data.at[i, 'Positionx']) and pd.notna(data.at[i, 'Positiony']) and \\\n",
    "           pd.notna(data.at[i-1, 'Positionx']) and pd.notna(data.at[i-1, 'Positiony']):\n",
    "            # Calculate the distance\n",
    "            dx = data.at[i, 'Positionx'] - data.at[i-1, 'Positionx']\n",
    "            dy = data.at[i, 'Positiony'] - data.at[i-1, 'Positiony']\n",
    "            distance = np.sqrt(dx**2 + dy**2)\n",
    "\n",
    "            # Calculate the time difference\n",
    "            dt = data.at[i, 'Time'] - data.at[i-1, 'Time']\n",
    "\n",
    "            # Calculate the speed\n",
    "            if dt != 0:\n",
    "                speed = distance / dt\n",
    "                data.at[i, 'Speed'] = speed\n",
    "\n",
    "    # Filter out rows where speed is greater than 2.57 and distance is greater than 8.5, delete these rows and all previous rows in the same trajectory\n",
    "    filtered_data = data[(data['Speed'] > abnormal_speed) & (data['Distance'] > settled_distance)]\n",
    "\n",
    "    # Identify the labels corresponding to these rows\n",
    "    labels_to_filter = filtered_data['Label'].unique()\n",
    "\n",
    "    # Iterate through each label that needs processing\n",
    "    for label in labels_to_filter:\n",
    "        label_data = data[data['Label'] == label]\n",
    "        # Find the last index to delete\n",
    "        max_index_to_delete = filtered_data[filtered_data['Label'] == label].index.max()\n",
    "        # Retain Time and ID columns, clear other columns\n",
    "        for row_index in label_data[label_data.index <= max_index_to_delete].index:\n",
    "            for col in data.columns:\n",
    "                if col not in ['Time', 'ID']:\n",
    "                    data.at[row_index, col] = np.nan  # Set to NaN\n",
    "\n",
    "    # Reset the index\n",
    "    data.reset_index(drop=True, inplace=True)\n",
    "\n",
    "    # Filter out rows where distance is greater than 48.35 and delete these rows and all previous rows in the same trajectory\n",
    "    \n",
    "    # Identify the rows that meet the condition\n",
    "    filtered_data = data[data['Distance'] > abnormal_distance]\n",
    "\n",
    "    # Identify labels corresponding to these rows\n",
    "    labels_to_filter = filtered_data['Label'].unique()\n",
    "\n",
    "    # Iterate through each label that needs processing\n",
    "    for label in labels_to_filter:\n",
    "        label_data = data[data['Label'] == label]\n",
    "        # Find the last index to delete\n",
    "        max_index_to_delete = filtered_data[filtered_data['Label'] == label].index.max()\n",
    "        # Retain Time and ID columns, clear other columns\n",
    "        for row_index in label_data[label_data.index <= max_index_to_delete].index:\n",
    "            for col in data.columns:\n",
    "                if col not in ['Time', 'ID']:\n",
    "                    data.at[row_index, col] = np.nan  # Set to NaN\n",
    "\n",
    "    # Reset the index\n",
    "    data.reset_index(drop=True, inplace=True)\n",
    "\n",
    "    # Filter out incomplete trajectories, i.e., those without distances falling within 1.8 and 7\n",
    "    data['Distance'] = pd.to_numeric(data['Distance'], errors='coerce')\n",
    "    # Step 1: Find the minimum and maximum distance for each trajectory\n",
    "    trajectory_stats = data.groupby('Label')['Distance'].agg(['min', 'max']).reset_index()\n",
    "    # Step 2: Identify incomplete trajectories\n",
    "    incomplete_trajectories = trajectory_stats[\n",
    "        ~((trajectory_stats['min'] < 1.8) & (trajectory_stats['max'] > 7))\n",
    "    ]['Label']\n",
    "\n",
    "    # Step 3: Set data to NaN for incomplete trajectories except for ID and Time\n",
    "    for label in incomplete_trajectories:\n",
    "        data.loc[data['Label'] == label, data.columns.difference(['Time', 'ID'])] = np.nan\n",
    "\n",
    "    # Remove stationary points during rest periods (considering the situation of immobility due to crowding)\n",
    "    speed_threshold = 0.1\n",
    "    distance_threshold = 2.7\n",
    "    consecutive_count_threshold = 20\n",
    "\n",
    "    # Store labels and indices that meet the condition\n",
    "    labels_to_remove = set()\n",
    "\n",
    "    # Iterate through each label\n",
    "    for label in data['Label'].unique():\n",
    "        if pd.notna(label):\n",
    "            label_data = data[data['Label'] == label]\n",
    "            consecutive_count = 0\n",
    "            for index, row in label_data.iterrows():\n",
    "                if pd.notna(row['Speed']) and row['Speed'] < speed_threshold and row['Distance'] > distance_threshold:\n",
    "                    consecutive_count += 1\n",
    "                    if consecutive_count > consecutive_count_threshold:\n",
    "                        labels_to_remove.add(label)\n",
    "                        break\n",
    "                else:\n",
    "                    consecutive_count = 0\n",
    "\n",
    "    deleted_rows = pd.DataFrame(columns=data.columns)\n",
    "\n",
    "    for label in labels_to_remove:\n",
    "        label_data = data[data['Label'] == label]\n",
    "        max_index_to_delete = label_data.index.max()\n",
    "        deleted_rows = pd.concat([deleted_rows, label_data[label_data.index <= max_index_to_delete]])\n",
    "        for row_index in label_data.index:\n",
    "            if row_index <= max_index_to_delete:\n",
    "                for col in data.columns:\n",
    "                    if col not in ['Time', 'ID']:\n",
    "                        data.at[row_index, col] = np.nan\n",
    "\n",
    "    data.reset_index(drop=True, inplace=True)\n",
    "\n",
    "    # Remove the points of idleness before the experiment ends\n",
    "    speed_threshold = 0.1\n",
    "    last_valid_index = data[data['Speed'] >= speed_threshold].index.max()\n",
    "    if not np.isnan(last_valid_index):\n",
    "        for row_index in range(last_valid_index + 1, len(data)):\n",
    "            for col in data.columns:\n",
    "                if col not in ['Time', 'ID']:\n",
    "                    data.at[row_index, col] = np.nan\n",
    "\n",
    "    data.reset_index(drop=True, inplace=True)\n",
    "\n",
    "    data['AngleChange'] = np.nan\n",
    "\n",
    "    # Function to calculate the change in angle\n",
    "    def calculate_angle_change(x0, y0, x1, y1, x2, y2):\n",
    "        v1 = np.array([x1 - x0, y1 - y0])\n",
    "        v2 = np.array([x2 - x1, y2 - y1])\n",
    "        dot_product = np.dot(v1, v2)\n",
    "        norm_v1 = np.linalg.norm(v1)\n",
    "        norm_v2 = np.linalg.norm(v2)\n",
    "        if norm_v1 == 0 or norm_v2 == 0:\n",
    "            return 0\n",
    "        cos_theta = dot_product / (norm_v1 * norm_v2)\n",
    "        cos_theta = np.clip(cos_theta, -1.0, 1.0)\n",
    "        angle = np.arccos(cos_theta) * 180 / np.pi\n",
    "        return angle\n",
    "\n",
    "    # Iterate and calculate the angle change for each trajectory point\n",
    "    for i in range(1, len(data) - 1):\n",
    "        if pd.notna(data.at[i-1, 'Positionx']) and pd.notna(data.at[i-1, 'Positiony']) and \\\n",
    "           pd.notna(data.at[i, 'Positionx']) and pd.notna(data.at[i, 'Positiony']) and \\\n",
    "           pd.notna(data.at[i+1, 'Positionx']) and pd.notna(data.at[i+1, 'Positiony']):\n",
    "            angle_change = calculate_angle_change(\n",
    "                data.at[i-1, 'Positionx'], data.at[i-1, 'Positiony'],\n",
    "                data.at[i, 'Positionx'], data.at[i, 'Positiony'],\n",
    "                data.at[i+1, 'Positionx'], data.at[i+1, 'Positiony']\n",
    "            )\n",
    "            data.at[i, 'AngleChange'] = angle_change\n",
    "\n",
    "    # Ensure the first row in each trajectory has NaN in the Speed column (no inertia)\n",
    "    unique_labels = data['Label'].dropna().unique()\n",
    "    for label in unique_labels:\n",
    "        first_index = data[data['Label'] == label].index.min()\n",
    "        data.at[first_index, 'Speed'] = np.nan\n",
    "    \n",
    "    # Calculate SpeedChange\n",
    "    data['SpeedChange'] = np.nan  # Create a new SpeedChange column and initialize it to NaN\n",
    "\n",
    "    # Iterate and calculate SpeedChange\n",
    "    for i in range(1, len(data)):\n",
    "        if pd.notna(data.at[i, 'Speed']) and pd.notna(data.at[i-1, 'Speed']):\n",
    "            data.at[i, 'SpeedChange'] = data.at[i, 'Speed'] - data.at[i-1, 'Speed']\n",
    "\n",
    "    return data  # Return the data for further use\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_traj(data, output_folder):\n",
    "    # Ensure the output folder exists\n",
    "    if not os.path.exists(output_folder):\n",
    "        os.makedirs(output_folder)\n",
    "\n",
    "    data_with_labels = data.dropna(subset=['Label'])\n",
    "    label_times = data_with_labels.groupby('Label')['Time'].agg(['min', 'max']).reset_index()\n",
    "\n",
    "    for label in label_times['Label'].unique():\n",
    "        track_data = data_with_labels[data_with_labels['Label'] == label]\n",
    "        if track_data.empty:\n",
    "            continue\n",
    "        track_data = track_data.dropna(subset=['Positionx', 'Positiony'])\n",
    "        start_time = label_times[label_times['Label'] == label]['min'].values[0]\n",
    "        end_time = label_times[label_times['Label'] == label]['max'].values[0]\n",
    "        participant_id = track_data['ID'].values[0]\n",
    "        fig, ax = plt.subplots()\n",
    "        ax.plot(track_data['Positionx'], track_data['Positiony'], marker='o')\n",
    "        ax.set_title(f'ID {participant_id} - Track {label} (Start: {start_time}, End: {end_time})')\n",
    "        ax.set_xlabel('Positionx')\n",
    "        ax.set_ylabel('Positiony')\n",
    "        ax.grid(True)\n",
    "        # Save the image to the specified folder\n",
    "        fig.savefig(os.path.join(output_folder, f'track_{participant_id}_label_{label}.png'))\n",
    "        plt.close(fig)  # Close the current figure to free memory\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define folder path\n",
    "folder_path = '/Users/yangfanzhou/Desktop/1.8/Experiment 2 data'\n",
    "image_output_folder = '/Users/yangfanzhou/Desktop/1.8/Experiment2_AllTrajectories'\n",
    "\n",
    "csv_file = glob.glob(os.path.join(folder_path, '*.csv'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/8t/9k64w8hn15ng50h2zwfs07tr0000gn/T/ipykernel_45401/297892584.py:194: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  deleted_rows = pd.concat([deleted_rows, label_data[label_data.index <= max_index_to_delete]])\n",
      "/var/folders/8t/9k64w8hn15ng50h2zwfs07tr0000gn/T/ipykernel_45401/297892584.py:194: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  deleted_rows = pd.concat([deleted_rows, label_data[label_data.index <= max_index_to_delete]])\n",
      "/var/folders/8t/9k64w8hn15ng50h2zwfs07tr0000gn/T/ipykernel_45401/297892584.py:194: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  deleted_rows = pd.concat([deleted_rows, label_data[label_data.index <= max_index_to_delete]])\n",
      "/var/folders/8t/9k64w8hn15ng50h2zwfs07tr0000gn/T/ipykernel_45401/297892584.py:194: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  deleted_rows = pd.concat([deleted_rows, label_data[label_data.index <= max_index_to_delete]])\n",
      "/var/folders/8t/9k64w8hn15ng50h2zwfs07tr0000gn/T/ipykernel_45401/297892584.py:194: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  deleted_rows = pd.concat([deleted_rows, label_data[label_data.index <= max_index_to_delete]])\n"
     ]
    }
   ],
   "source": [
    "process_dfs = []\n",
    "\n",
    "# Loop through each file in csv_file\n",
    "for file in csv_file:\n",
    "    # Process each file and store the resulting DataFrame\n",
    "    process_df = process_file(file)\n",
    "    process_dfs.append(process_df)\n",
    "    \n",
    "    # Generate trajectory plots for each processed DataFrame\n",
    "    plot_traj(process_df, image_output_folder)\n",
    "\n",
    "# Combine all processed DataFrames into one DataFrame\n",
    "combined_df = pd.concat(process_dfs, ignore_index=True)\n",
    "\n",
    "# Display the combined DataFrame (optional, depending on your environment)\n",
    "combined_df\n",
    "\n",
    "# Save the combined DataFrame to the specified Excel file\n",
    "output_excel_path = '/Users/yangfanzhou/Desktop/1.8/ResultWholeDistance/Experiment2_Data.xlsx'\n",
    "combined_df.to_excel(output_excel_path, index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
